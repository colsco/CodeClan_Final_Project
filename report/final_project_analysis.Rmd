---
title: 'CodeClan Final Project: UK Productivity'
author: Colin Scotland | DE13
date: "30/05/2022"
output:
  html_document:
    code_folding: hide
    theme: cerulean
    toc: yes
    toc_float: yes
    toc_depth: 4
  pdf_document:
    toc: yes
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE}
library(here)
here::here()

```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
source(here("data_cleaning/cleaning.R"))
```
# Initial Plots

## UK Output per Hour Ranking v Europe

```{r}
# UK Output per Hour Ranking v Europe ----


europe_labour_prod %>% 
  group_by(country) %>% 
  ggplot() +
  aes(x = reorder(country, value), 
      y = value, 
      group = country, 
      fill = country == "United Kingdom") +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE) +
  scale_fill_manual(values = c("grey90", "orange")) +
  theme_light(base_size = 10) +
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  labs(x = "Country\n",
       y = "Distribution of Output per Hour per Industry (€)",
       title = "Comparison of Industrial Output per Hour in the EU 2014 - 2016 (€)") +
  coord_flip()

```
<br>
The boxplot shows that despite the UK's political stance on the global stage and
it's reputation as a financial powerhouse, in reality the overall productivity
is at best fairly mediocre even when compared to countries within the EU. 

Spain's recent history has seen high unemployment and even depopulation in 
certain interior regions, yet it ranks better than the UK.  Successive UK 
governments have looked to minimise the strength of trade unions, yet countries
in which trade unions remain powerful and are often associated with strike action, 
such as France and Germany are also ranked above the UK.

Ireland, our nearest neighbour with an education and industrial profile very 
similar to the UK comes far higher up in the rankings, which begs the question
"what is UK industry not getting right?".  However, it is also clear that there 
is a lot of overlap throughout all nations, so;

### Is the difference between Norway and the UK statistically significant?

## Hypothesis Test of Significance between UK and Norway Productivity

```{r}
europe_labour_prod %>% 
  group_by(country) %>% 
  filter(country == "Norway"| country == "United Kingdom") %>% 
  ggplot() +
  aes(x = country,  
      y = value, 
      group = country, 
      fill = country == "United Kingdom") +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE, fill = "grey90") +
  stat_summary(fun.y = "mean", 
               geom = "text", 
               label="mean ------------------------------------", 
               size= 4, 
               color= "orange") +
  theme_light(base_size = 10) +
  labs(x = "Country\n",
       y = "Distribution of Output per Hour per Industry (€)",
       title = "Comparison of Industrial Output per Hour, Norway v UK 2014 - 2016 (€)") 
  
```
<br>
The data for Norway is right-skewed and this has affected the mean relative to 
the overall distribution.  Consequently, median will be used in this hypothesis 
test.

The hypotheses under test are, with α = 0.05;

H0: The average output per hour in Norway is the same as in the UK

$$ H_0 : x͂_{Norway} - x͂_{UK} = 0 $$

H1: The average output per hour in Norway is significantly higher than in the UK

$$ H_1 : x͂_{Norway} - x͂_{UK} > 0 $$
<br>
In this case the median will be used, because the mean (dotted orange line on 
the boxplot above) is badly right skewed by outliers in Norway.


```{r}
uk_norway <- europe_labour_prod %>% 
  filter(country %in% c("United Kingdom", "Norway")) %>%
  group_by(country) %>% 
  select(-c(industry_group, industry))
           
  
```

Permutation to generate the null distribution


Under \(H_0\) the location of the apartment would have no bearing on the price, 
i.e. the location and price are independent. There would be no difference between 
groups.

By randomly shuffling (i.e. permuting) the locations labels we lose any 
relationship that there was between location and price. Think of this shuffling 
as detaching the labels from rows and then randomly assigning them back to rows. 
Then we see which of the following occurs:
If there was no relationship in the first place (i.e. they are in fact 
independent) then randomly shuffling them should have no implication.
If the difference between groups in our sample is much larger than the difference 
once the labels are shuffled it’s because there is a real difference between the 
groups, and it’s not just down to sampling variation.






Calculate the null sampling distribution;
```{r}
null_distribution <- uk_norway %>% 
  specify(value ~ country) %>% 
  infer::hypothesize(null = "independence") %>%         # 'infer' masked by 'fable'
  infer::generate(reps = 1000, type = "permute") %>%    # 'infer' masked by 'fable'
  calculate(stat = "diff in medians", order = c("Norway", "United Kingdom"))
# sample stat is median of Norway minus median of UK, so this is the order 
# we specify in the calculate step

head(null_distribution)
  
```

And now visualise the observed stat against the null distribution;

```{r}
observed_stat_norway_uk <- uk_norway %>% 
  specify(value ~ country) %>% 
  calculate("diff in medians", order = c("Norway", "United Kingdom"))

observed_stat_norway_uk
```


H1 is a "greater than" clause, so that means this is a one-sided test in the
"right" direction.

```{r}
null_distribution %>% 
  visualise(bins = 30) +
  theme_light(base_size = 10) +
  shade_p_value(obs_stat = observed_stat_norway_uk, direction = "right")
```

This gives a p-value of;
```{r}
p_value <- null_distribution %>%
  get_p_value(obs_stat = observed_stat_norway_uk, direction = "right")
p_value
```

The p-value of 0.63 is greater than α = 0.05.  In this case we fail to reject 
the null hypothesis and cannot say that there is a significant difference 
between the median hourly output in Norway when compared to the median hourly 
output in the United Kingdom.


# European Education Levels

```{r}
eu_lab_edu %>% 
  ungroup() %>% 
  ggplot() +
  aes(x = education_score, y = avg_prod) + 
  geom_point(size = 1, alpha = 0.3) +
  facet_wrap( ~ country) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.3)) +
  labs(title = "% Tertiary Educated v Productivity by Country, 2005 - 2015",
       x = "\n% Population with Tertiary Education by year 2005 - 2015",
       y = "Mean Productivity Score ($US Output per hour)\n") +
  scale_y_continuous(breaks = seq(50, 100, by = 25)) +
  geom_text(aes(label = year), 
            color = "black", 
            size = 2,
            nudge_y = 10,
            check_overlap = TRUE,
            alpha = 0.4)
  
```

The faceted scatterplot above suggests no obvious correlation between education
level and productivity level per country over time.  A correlation matrix might 
shed some more light on this:

```{r}
eu_lab_edu %>% 
  select(year, avg_prod, education_score) %>% 
  ggcorr(label = TRUE) +
  labs(title = "Correlation Matrix of Tertiary Education and Productivity by Country") +
  theme(title = element_text(face = "bold"))
```

The data actually suggests a weak negative correlation between productivity and
proportion of the workforce who have gone through tertiary education.  In other 
words, a weak suggestion that the lower the proportion of educated individuals,
the higher the national productivity!

The matrix also suggests that there is not correlation between productivity and 
year for the data used.


## UK Output per Hour per Industry 

```{r}
# Need a definition of industries - join with industry_dict.

region_by_industry_output_joined <- region_by_industry_output_per_hour %>% 
  left_join(industry_dict, by = "industry") 

# There were some industries grouped together that will need to be explained -
# they have probably been coerced to NAs during the join:

region_by_industry_output_joined %>% 
  filter(is.na(industry_group)) %>% 
  distinct(industry)
```
NAs have been returned only for the industry groupings;

* 'ALLINDUSTRIES'
* 'ABDE'
* 'ST'

For the purposes of this plot;

* 'ALLINDUSTRIES' can be removed.
* 'ABDE' can be defined as 'Agriculture, mining, water, electricity'
* 'ST' can be defined as 'Other services and domestic'

```{r}
region_by_industry_output_joined <- region_by_industry_output_joined %>% 
  mutate(industry_group = 
           if_else(industry == "ABDE", 
                   "agriculture mining water electricity", 
                   industry_group),
         industry_group = 
           if_else(industry == "ST", 
                   "other services and domestic", 
                   industry_group)
         ) %>% 
  filter(!is.na(industry_group))


# Limit timeframe to 2014 - 2016 to maintain consistency with EU data

region_by_industry_output_joined %>% 
  filter(year >= 2014) %>% 
  group_by(industry_group) %>% 
  ggplot() +
  aes(x = reorder(industry_group, pounds_per_hour_worked),
      y = pounds_per_hour_worked,
      group = industry_group) +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE, fill = "grey90") +
  theme_light(base_size = 10) +
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  labs(x = "UK Industry in order of Mean Output per Hour\n",
       y = "Distribution of Output per Hour per Industry (£ CVM)",
       title = "Comparison of Output per Hour in UK Industry\n2014 - 2016") +
  scale_x_discrete(labels = wrap_format(40)) +
  coord_flip()

```
<br>
This boxplot shows the distribution of output in pounds per hour worked per 
industry between 2014 - 2016.

The plot clearly shows that real estate was by far the largest contributor to 
financial productivity in this timeframe.

Among the rest of the industries, the plot shows that the hourly output of 
financial, agriculture and information communication contribute on average a 
larger financial output per hour worked than for example, administrative support,
accommodation and arts and entertainment.

It's also clear from the plot that there is a good deal of overlap through almost
all industry groups outside of real estate, i.e. there are no single industry 
groups that stand alone as being worse than all others.  


## UK Output per Hour per Region

```{r}

# Limit timeframe to 2014 - 2016 to maintain consistency with EU data


region_by_industry_output_joined %>% 
  filter(year >= 2014) %>% 
  filter(region != "uk") %>% 
  group_by(region) %>% 
  ggplot() +
  aes(x = reorder(region, pounds_per_hour_worked),
      y = pounds_per_hour_worked,
      group = region) +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE, fill = "grey90") +
  theme_light(base_size = 10) +
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  labs(x = "UK Region in order of Mean Output per Hour\n",
       y = "Distribution of Pounds Output per Hour per UK Region (£)",
       title = "Comparison of Industrial Output per Hour in UK Regions\n2014 - 2016") +
  scale_x_discrete(labels = wrap_format(40)) +
  coord_flip()
  
```

<br>
Comparison of the hourly output per UK region also shows a lot of overlap, with 
London at the top.  

## Hypothesis Test of Significance between London and Wales

First of all, it would help to visualise this comparison in more detail;

```{r}
region_by_industry_output_joined %>% 
  filter(year >= 2014) %>% 
  filter(region == "london" | region == "wales") %>%
  group_by(region) %>% 
  ggplot() +
  aes(x = region,
      y = pounds_per_hour_worked,
      group = region) +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE, 
               fill = "grey90") +
  stat_summary(fun.y = "mean", 
               geom = "text", 
               label="mean ------------------------------------", 
               size= 4, 
               color= "orange") +
  theme_light(base_size = 10) +
  labs(x = "UK Region in order of Mean Output per Hour\n",
       y = "Distribution of Pounds Output per Hour per UK Region (£)",
       title = "Comparison of Industrial Output per Hour in London and Wales\n2014 - 2016") +
  scale_x_discrete(labels = wrap_format(40)) +
  coord_cartesian(xlim = c(), ylim = c(0, 100)) 
# Use coord cartesian to limit the axis scales so that the mean and median are
# not affected (they are affected if scale_y_continuous(limits = ) is used)
```
<br>
The hypotheses for this are as follows, with α = 0.05;

H0: The average output per hour in London is the same as in Wales

$$ H_0 : x͂_{London} - x͂_{Wales} = 0 $$

H1: The average output per hour in London is significantly higher than in Wales

$$ H_1 : x͂_{London} - x͂_{Wales} > 0 $$
<br>
In this case the median will be used, because the mean (dotted orange line on 
the boxplot above) is badly right skewed by outliers in both data sets.

```{r}
london_wales <- region_by_industry_output_joined %>% 
  filter(year >= 2014) %>% 
  filter(region %in% c("wales", "london")) %>%
  group_by(region) %>% 
  select(-c(year, industry))
           
  
```

Permutation to generate the null distribution


Under \(H_0\) the location of the apartment would have no bearing on the price, 
i.e. the location and price are independent. There would be no difference between 
groups.

By randomly shuffling (i.e. permuting) the locations labels we lose any 
relationship that there was between location and price. Think of this shuffling 
as detaching the labels from rows and then randomly assigning them back to rows. 
Then we see which of the following occurs:
If there was no relationship in the first place (i.e. they are in fact 
independent) then randomly shuffling them should have no implication.
If the difference between groups in our sample is much larger than the difference 
once the labels are shuffled it’s because there is a real difference between the 
groups, and it’s not just down to sampling variation.




Calculate the null sampling distribution;
```{r}
null_distribution <- london_wales %>% 
  specify(pounds_per_hour_worked ~ region) %>% 
  infer::hypothesize(null = "independence") %>%           # 'infer' masked by 'fable'
  infer::generate(reps = 1000, type = "permute") %>%      # 'infer' masked by 'fable'
  calculate(stat = "diff in medians", order = c("london", "wales"))
# sample stat is median of London minus median of Wales, so this is the order 
# we specify in the calculate step

head(null_distribution)
  
```

And now visualise the observed stat against the null distribution;

```{r}
observed_stat_lond_wal <- london_wales %>% 
  specify(pounds_per_hour_worked ~ region) %>% 
  calculate("diff in medians", order = c("london", "wales"))

observed_stat_lond_wal
```


H1 is a "greater than" clause, so that means this is a one-sided test in the
"right" direction.

```{r}
null_distribution %>% 
  visualise(bins = 30) +
  theme_light(base_size = 10) +
  shade_p_value(obs_stat = observed_stat_lond_wal, direction = "right")
```

This gives a p-value of;
```{r}
p_value <- null_distribution %>%
  get_p_value(obs_stat = observed_stat_lond_wal, direction = "right")
p_value
```

The p-value is less than α = 0.05.  In this case we reject the null hypothesis 
and can say that for this data there is a significant difference between the 
median hourly output in London when compared to the median hourly output in Wales.

## Output by Industry by Region 

One other point of interest is the output per industry per region;

```{r}
model_base_data %>% 
  select(region, industry_group, pounds_per_hour_worked) %>% 
  group_by(region, industry_group) %>% 
  ggplot() +
  aes(x = reorder(industry_group, pounds_per_hour_worked),
      y = log(pounds_per_hour_worked), colour = region) +
  geom_point(alpha = 0.3) +
  theme_light() +
  labs(title = "Productivity per Industry by UK Region",
       x = "Industry",
       y = "log(Pounds Output per Hour Worked)") +
  scale_x_discrete(labels = wrap_format(40)) +
  coord_flip()
```

<br>


### Agriculture, Mining, Water, Electricity

This industry grouping shows a very large spread of productivity which appears
to be dependent on region:

```{r}
model_base_data %>% 
  filter(industry == "ABDE") %>% 
  select(region, industry_group, pounds_per_hour_worked) %>% 
  group_by(region, industry_group) %>% 
  ggplot() +
  aes(x = reorder(industry_group, pounds_per_hour_worked),
      y = pounds_per_hour_worked, colour = region) +
  geom_jitter(height = 0.1) +
  theme_light() +
  labs(title = "Agriculture, Mining, Water, Electricity Productivity by UK Region",
       y = "Pounds Output per Hour Worked") +
  theme(axis.title.x = element_blank ()) +
  scale_colour_brewer(palette = "Set3")
```


This clearly shows stratification based on region, but there is insufficient data 
to be able to pinpoint exactly what is creating the difference.  Is this more 
evident in a boxplot?

```{r}
model_base_data %>% 
  filter(industry == "ABDE") %>% 
  select(region, industry_group, pounds_per_hour_worked) %>% 
  group_by(region, industry_group) %>% 
  ggplot() +
  aes(x = reorder(region, pounds_per_hour_worked),
      y = pounds_per_hour_worked) +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(fill = "grey90") +
  theme_light() +
  labs(title = "Agriculture, Mining, Water, Electricity Productivity by UK Region",
       x = "UK Region",
       y = "Pounds Output per Hour Worked") +
  coord_flip()
```

Comparing London with Wales and N. Ireland there is very clearly a difference.

It's not clear exactly how Agriculture, Mining, Water and Electricity output are
measured, but there's more scope for investigation in this respect.  Doing so
may provide an insight into improvement methodologies for the lower-scoring 
regions.  
<br>


## Can UK Commuting Data be added to the model?

```{r}
model_commute_region %>% 
  filter(region != "total") %>% 
  mutate(commute_time = fct_relevel(commute_time, c("under_15min", 
                                                    "btwn_16_30min", 
                                                    "btwn_31_45min", 
                                                    "btwn_46_60min", 
                                                    "over_61min"))) %>% 
  mutate(region = as.factor(region)) %>% 
  mutate(region = fct_relevel(region, c("london",
                                        "southeast",
                                        "scotland",
                                        "east",
                                        "eastmidlands",
                                        "yorkshirehumber",
                                        "northernireland",
                                        "westmidlands",
                                        "southwest",
                                        "northeast",
                                        "northwest",
                                        "wales"))) %>% 
  # factor_relevel to set the correct order of x-axis labels
  ggplot() + 
  aes(x = commute_time, y = pcntge_workforce) + 
  geom_col(fill = "grey80", colour = "black") +
  facet_wrap(~ region, nrow = 2) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.3)) +
  labs(title = "Commute Time per % Workforce by UK Region",
       x = "\nCommute Time",
       y = "Proportion of Workforce\n")
```
# Does employee age matter?

Pivot the data longer then change characters to factors;

```{r}
model_ages_long <- model_ages %>% 
  pivot_longer(cols = contains("age"), 
               names_to = "employee_age", 
               values_to = "no_employed") %>% 
  select(-industry) %>% 
  mutate(across(where(is.character), .fns = as.factor))
  
```


```{r}
model_ages_long %>% 
  ggplot() +
  aes(x = year) + 
  geom_line(aes(y = no_employed/1000000, 
      group = employee_age,
      colour = employee_age)) +
#  geom_line(aes(y = pounds_per_hour_worked, group = 1)) +
  geom_text(x = 2003,  y = 28, 
           label = "Pounds per hour worked", 
           colour = "black",
           size = 3) +
  theme_light() +
  labs(title = "UK Employment Numbers per Age Group",
       x = "Year",
       y = "No. Employed (millions)") +
  theme(legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  scale_x_continuous(breaks=seq(1997, 2022, 1)) +
  scale_colour_discrete(labels = c("16 - 17 years old", 
                                 "18 - 24 years old", 
                                 "25 - 34 years old",
                                 "35 - 49 years old",
                                 "50 - 64 years old",
                                 "> 65 years old"))
```



# Explanatory Model Setup: Region, No. Jobs, Industry Type

```{r}
model_dev <- model_base_data %>% 
  select(-c(year, industry)) %>% 
  mutate(year = year(quarter), .after = quarter)
```

#### Set Test-Train Split

`model_dev` contains over 3600 observations, so an 80/20 train/test split would
give almost 2900 rows for training and around 750 rows for testing.

```{r}

# Change character variables to factors
model_dev <- model_dev %>% 
  mutate(region = as.factor(region),
         industry_group = as.factor(industry_group))


# Make a test index
test_index <- sample(1:nrow(model_dev), size = nrow(model_dev)*0.2)

# Use the test index to create test and training datasets
model_test  <- slice(model_dev, test_index)
model_train <- slice(model_dev, -test_index)
```




#### mod1a - Training Data

```{r}

mod1a_exh <- regsubsets(pounds_per_hour_worked ~ ., 
                            data = model_train,
                            method = "exhaustive")
```

```{r}
summary_mod1a_exh <- summary(mod1a_exh)
summary_mod1a_exh
```

It looks like industry type (particularly real estate and financial services) 
and region have an influence on productivity, along with `year` to a lesser 
extent.  The average number of jobs in each region is insignificant.

```{r}
plot(mod1a_exh, scale = "adjr2")
```

The plot confirms the original suggestion.  Check against BIC:

```{r}
plot(mod1a_exh, scale = "bic")
```


The lowest BIC score comes with industry type, region and year.

Although only certain industries and regions have been shown above to be influential 
predictors, they cannot be selected individually.  If one industry or region is 
selected then they all need to be included.

The biggest influence comes from industry type.

```{r}
mod1a_no_industry <- lm(pounds_per_hour_worked ~ region + year, 
                        data = model_train)
summary(mod1a_no_industry)
```

```{r}
mod1a_with_industry <- lm(pounds_per_hour_worked ~ industry_group + region + year, 
                        data = model_train)
summary(mod1a_with_industry)
```

```{r}
anova(mod1a_no_industry, mod1a_with_industry)
```

The model with `industry_group` is more significant than the model without, 
so it should be the main part of the model.

```{r}
autoplot(mod1a_with_industry)
```


### Model with Test Data


```{r}

mod1_test <- regsubsets(pounds_per_hour_worked ~ ., 
                            data = model_test,
                            method = "exhaustive")
```

```{r}
summary_mod1_test <- summary(mod1_test)
summary_mod1_test
```

In the test data, region and year are less influential and the average number of
jobs per region is more influential.


```{r}
plot(mod1_test, scale = "adjr2")
```

The plot confirms the original suggestion although region is absent from the 
test data result.  Check against BIC:

```{r}
plot(mod1_test, scale = "bic")
```


Again, region and industry are the main influencing factors.

Although only certain industries have been shown to be influential predictors, 
they cannot be selected individually.  If one industry or region is selected 
then they all need to be included.

Check which predictors are most significant;
```{r}
mod1_test_no_industry <- lm(pounds_per_hour_worked ~ region + year, 
                        data = model_dev)
summary(mod1_test_no_industry)
```

```{r}
mod1_test_with_industry <- lm(pounds_per_hour_worked ~ industry_group + region + year, 
                        data = model_dev)
summary(mod1_test_with_industry)
```

The summary above suggests that with the test data, the model accounts for 89%
of variation in the data.

```{r}
anova(mod1_test_no_industry, mod1_test_with_industry)
```

The model with `industry_group` is still more significant than the model without, 
so it should be the main part of the model.

```{r}
autoplot(mod1_test_with_industry)
```


# Explanatory Model Summary

The diagnostic plots show a reasonable residuals v fitted, with a spread over 
the x-axis and a horizontal line, although there is some grouping evident.

The Q-Q plot lies along the line for the most part, although again the relationship
is not completely normal and scale-location shows some evidence of funneling.

In summary, the productivity within the UK can be described as factors of
industry type and region, or:

$$ pounds\_per\_hour\_worked \sim industry\_group + region + year $$


# Time Series Productivity Per Industry

```{r}
region_by_industry_output_joined %>% 
  filter(region == "uk") %>% 
  group_by(industry_group) %>% 
  ggplot() +
  aes(x = year,
      y = log(pounds_per_hour_worked),
      group = industry_group,
      colour = industry_group) +
  theme_light() +
  scale_colour_discrete(labels = function(x) str_wrap(x, width = 35)) +
  theme(legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  geom_line() +
  labs(title = "Time Series Plot of log(Productivity) by Industry",
       x = "Year",
       y = "log(Pounds Generated per Hour Worked") +
  scale_x_continuous(breaks=seq(1997, 2022, 1))
  
```
# Explanatory Model 2: Education

An explanatory model describing the influence of education had been planned, but
after cleaning for UK data there were only 20 observations upon which to build
a model, which seems insufficient to develop a test train split.  Is cross 
validation an option?


# Generate a Time Series for Forecasting


```{r}
model_fcast <- region_by_industry_output_joined %>% 
  select(-industry) %>% 
  filter(region == "uk") %>% 
  group_by(year) %>% 
  summarise(annual_total = sum(pounds_per_hour_worked))
  

model_fcast <- tsibble(model_fcast, index = "year")

```


```{r}
model_fcast %>% 
  autoplot(annual_total) +
  theme_light() +
  scale_colour_discrete(labels = function(x) str_wrap(x, width = 35)) +
  theme(legend.title = element_blank()) +
  labs(title = "Autoplot of Total Productivity over Time UK",
       x = "Year",
       y = "Productivity") +
  scale_x_continuous(breaks=seq(1997, 2022, 1)) +
  annotate("text", x = 2010, y = 650, 
           label = "2009 Financial\nCrisis",
           colour = "grey40") +
  geom_abline()
```


# Forecast Model 

```{r}
fit <- model_fcast %>%
  model(arima = ARIMA(annual_total),
        ets = ETS(annual_total))

fit
```

```{r}
forecast_1 <- fit %>%
  fabletools::forecast(h = "6 years")
forecast_1
```



```{r}

forecast_1 %>%
autoplot(annual_total) +
    guides(colour = guide_legend(title = "Forecast"))

```







