---
title: 'CodeClan Final Project: UK Productivity'
author: Colin Scotland | DE13
date: "30/05/2022"
output:
  html_document:
    code_folding: hide
    theme: cerulean
    toc: yes
    toc_float: yes
    toc_depth: 4
  pdf_document:
    toc: yes
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = FALSE}
library(here)
here::here()

```

```{r}
source(here("data_cleaning/cleaning.R"))
```
# Initial Plots

## UK Output per Hour Ranking v Europe

```{r}
# UK Output per Hour Ranking v Europe ----


europe_labour_prod %>% 
  group_by(country) %>% 
  ggplot() +
  aes(x = reorder(country, value), 
      y = value, 
      group = country, 
      fill = country == "United Kingdom") +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE) +
  scale_fill_manual(values = c("grey90", "orange")) +
  theme_light(base_size = 10) +
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  labs(x = "Country\n",
       y = "Distribution of Output per Hour per Industry (€)",
       title = "Comparison of Industrial Output per Hour in the EU 2014 - 2016 (€)") +
  coord_flip()

```
<br>
The boxplot shows that despite the UK's political stance on the global stage and
it's reputation as a financial powerhouse, in reality the overall productivity
is at best fairly mediocre even when compared to countries within the EU. 

Spain's recent history has seen high unemployment and even depopulation in 
certain interior regions, yet it ranks better than the UK.  Successive UK 
governments have looked to minimise the strength of trade unions, yet countries
in which trade unions remain powerful and are often associated with strike action, 
such as France and Germany are also ranked above the UK.

Ireland, our nearest neighbour with an education and industrial profile very 
similar to the UK comes far higher up in the rankings, which begs the question
"what is UK industry not getting right?".  However, it is also clear that there 
is a lot of overlap throughout all nations, so;

### Is the difference between Norway and the UK statistically significant?

## Hypothesis Test of Significance between UK and Norway Productivity

```{r}
europe_labour_prod %>% 
  group_by(country) %>% 
  filter(country == "Norway"| country == "United Kingdom") %>% 
  ggplot() +
  aes(x = country,  
      y = value, 
      group = country, 
      fill = country == "United Kingdom") +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE, fill = "grey90") +
  stat_summary(fun.y = "mean", 
               geom = "text", 
               label="mean ------------------------------------", 
               size= 4, 
               color= "orange") +
  theme_light(base_size = 10) +
  labs(x = "Country\n",
       y = "Distribution of Output per Hour per Industry (€)",
       title = "Comparison of Industrial Output per Hour, Norway v UK 2014 - 2016 (€)") 
  
```
<br>
The data for Norway is right-skewed and this has affected the mean relative to 
the overall distribution.  Consequently, median will be used in this hypothesis 
test.

The hypotheses under test are, with α = 0.05;

H0: The average output per hour in Norway is the same as in the UK

$$ H_0 : x͂_{Norway} - x͂_{UK} = 0 $$

H1: The average output per hour in Norway is significantly higher than in the UK

$$ H_1 : x͂_{Norway} - x͂_{UK} > 0 $$
<br>
In this case the median will be used, because the mean (dotted orange line on 
the boxplot above) is badly right skewed by outliers in Norway.


```{r}
uk_norway <- europe_labour_prod %>% 
  filter(country %in% c("United Kingdom", "Norway")) %>%
  group_by(country) %>% 
  select(-c(industry_group, industry))
           
  
```

Permutation to generate the null distribution


Under \(H_0\) the location of the apartment would have no bearing on the price, 
i.e. the location and price are independent. There would be no difference between 
groups.

By randomly shuffling (i.e. permuting) the locations labels we lose any 
relationship that there was between location and price. Think of this shuffling 
as detaching the labels from rows and then randomly assigning them back to rows. 
Then we see which of the following occurs:
If there was no relationship in the first place (i.e. they are in fact 
independent) then randomly shuffling them should have no implication.
If the difference between groups in our sample is much larger than the difference 
once the labels are shuffled it’s because there is a real difference between the 
groups, and it’s not just down to sampling variation.






Calculate the null sampling distribution;
```{r}
null_distribution <- uk_norway %>% 
  specify(value ~ country) %>% 
  infer::hypothesize(null = "independence") %>%         # 'infer' masked by 'fable'
  infer::generate(reps = 1000, type = "permute") %>%    # 'infer' masked by 'fable'
  calculate(stat = "diff in medians", order = c("Norway", "United Kingdom"))
# sample stat is median of Norway minus median of UK, so this is the order 
# we specify in the calculate step

head(null_distribution)
  
```

And now visualise the observed stat against the null distribution;

```{r}
observed_stat_norway_uk <- uk_norway %>% 
  specify(value ~ country) %>% 
  calculate("diff in medians", order = c("Norway", "United Kingdom"))

observed_stat_norway_uk
```


H1 is a "greater than" clause, so that means this is a one-sided test in the
"right" direction.

```{r}
null_distribution %>% 
  visualise(bins = 30) +
  theme_light(base_size = 10) +
  shade_p_value(obs_stat = observed_stat_norway_uk, direction = "right")
```

This gives a p-value of;
```{r}
p_value <- null_distribution %>%
  get_p_value(obs_stat = observed_stat_norway_uk, direction = "right")
p_value
```

The p-value of 0.63 is greater than α = 0.05.  In this case we fail to reject 
the null hypothesis and cannot say that there is a significant difference 
between the median hourly output in Norway when compared to the median hourly 
output in the United Kingdom.

## UK Output per Hour per Industry 

```{r}
# Need a definition of industries - join with industry_dict.

region_by_industry_output_joined <- region_by_industry_output_per_hour %>% 
  left_join(industry_dict, by = "industry") 

# There were some industries grouped together that will need to be explained -
# they have probably been coerced to NAs during the join:

region_by_industry_output_joined %>% 
  filter(is.na(industry_group)) %>% 
  distinct(industry)
```
NAs have been returned only for the industry groupings;

* 'ALLINDUSTRIES'
* 'ABDE'
* 'ST'

For the purposes of this plot;

* 'ALLINDUSTRIES' can be removed.
* 'ABDE' can be defined as 'Agriculture, mining, water, electricity'
* 'ST' can be defined as 'Other services and domestic'

```{r}
region_by_industry_output_joined <- region_by_industry_output_joined %>% 
  mutate(industry_group = 
           if_else(industry == "ABDE", 
                   "agriculture mining water electricity", 
                   industry_group),
         industry_group = 
           if_else(industry == "ST", 
                   "other services and domestic", 
                   industry_group)
         ) %>% 
  filter(!is.na(industry_group))


# Limit timeframe to 2014 - 2016 to maintain consistency with EU data

region_by_industry_output_joined %>% 
  filter(year >= 2014) %>% 
  group_by(industry_group) %>% 
  ggplot() +
  aes(x = reorder(industry_group, pounds_per_hour_worked),
      y = pounds_per_hour_worked,
      group = industry_group) +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE, fill = "grey90") +
  theme_light(base_size = 10) +
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  labs(x = "UK Industry in order of Mean Output per Hour\n",
       y = "Distribution of Output per Hour per Industry (£ CVM)",
       title = "Comparison of Output per Hour in UK Industry\n2014 - 2016") +
  scale_x_discrete(labels = wrap_format(40)) +
  coord_flip()

```
<br>
This boxplot shows the distribution of output in pounds per hour worked per 
industry between 2014 - 2016.

The plot clearly shows that real estate was by far the largest contributor to 
financial productivity in this timeframe.

Among the rest of the industries, the plot shows that the hourly output of 
financial, agriculture and information communication contribute on average a 
larger financial output per hour worked than for example, administrative support,
accommodation and arts and entertainment.

It's also clear from the plot that there is a good deal of overlap through almost
all industry groups outside of real estate, i.e. there are no single industry 
groups that stand alone as being worse than all others.  


## UK Output per Hour per Region

```{r}

# Limit timeframe to 2014 - 2016 to maintain consistency with EU data


region_by_industry_output_joined %>% 
  filter(year >= 2014) %>% 
  filter(region != "uk") %>% 
  group_by(region) %>% 
  ggplot() +
  aes(x = reorder(region, pounds_per_hour_worked),
      y = pounds_per_hour_worked,
      group = region) +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE, fill = "grey90") +
  theme_light(base_size = 10) +
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1))+
  labs(x = "UK Region in order of Mean Output per Hour\n",
       y = "Distribution of Pounds Output per Hour per UK Region (£)",
       title = "Comparison of Industrial Output per Hour in UK Regions\n2014 - 2016") +
  scale_x_discrete(labels = wrap_format(40)) +
  coord_flip()
  
```

<br>
Comparison of the hourly output per UK region also shows a lot of overlap, with 
London at the top.  

## Hypothesis Test of Significance between London and Wales

First of all, it would help to visualise this comparison in more detail;

```{r}
region_by_industry_output_joined %>% 
  filter(year >= 2014) %>% 
  filter(region == "london" | region == "wales") %>%
  group_by(region) %>% 
  ggplot() +
  aes(x = region,
      y = pounds_per_hour_worked,
      group = region) +
  stat_boxplot(geom = "errorbar") +
  geom_boxplot(show.legend = FALSE, 
               fill = "grey90") +
  stat_summary(fun.y = "mean", 
               geom = "text", 
               label="mean ------------------------------------", 
               size= 4, 
               color= "orange") +
  theme_light(base_size = 10) +
  labs(x = "UK Region in order of Mean Output per Hour\n",
       y = "Distribution of Pounds Output per Hour per UK Region (£)",
       title = "Comparison of Industrial Output per Hour in London and Wales\n2014 - 2016") +
  scale_x_discrete(labels = wrap_format(40)) +
  coord_cartesian(xlim = c(), ylim = c(0, 100)) 
# Use coord cartesian to limit the axis scales so that the mean and median are
# not affected (they are affected if scale_y_continuous(limits = ) is used)
```
<br>
The hypotheses for this are as follows, with α = 0.05;

H0: The average output per hour in London is the same as in Wales

$$ H_0 : x͂_{London} - x͂_{Wales} = 0 $$

H1: The average output per hour in London is significantly higher than in Wales

$$ H_1 : x͂_{London} - x͂_{Wales} > 0 $$
<br>
In this case the median will be used, because the mean (dotted orange line on 
the boxplot above) is badly right skewed by outliers in both data sets.

```{r}
london_wales <- region_by_industry_output_joined %>% 
  filter(year >= 2014) %>% 
  filter(region %in% c("wales", "london")) %>%
  group_by(region) %>% 
  select(-c(year, industry))
           
  
```

Permutation to generate the null distribution


Under \(H_0\) the location of the apartment would have no bearing on the price, 
i.e. the location and price are independent. There would be no difference between 
groups.

By randomly shuffling (i.e. permuting) the locations labels we lose any 
relationship that there was between location and price. Think of this shuffling 
as detaching the labels from rows and then randomly assigning them back to rows. 
Then we see which of the following occurs:
If there was no relationship in the first place (i.e. they are in fact 
independent) then randomly shuffling them should have no implication.
If the difference between groups in our sample is much larger than the difference 
once the labels are shuffled it’s because there is a real difference between the 
groups, and it’s not just down to sampling variation.




Calculate the null sampling distribution;
```{r}
null_distribution <- london_wales %>% 
  specify(pounds_per_hour_worked ~ region) %>% 
  infer::hypothesize(null = "independence") %>%           # 'infer' masked by 'fable'
  infer::generate(reps = 1000, type = "permute") %>%      # 'infer' masked by 'fable'
  calculate(stat = "diff in medians", order = c("london", "wales"))
# sample stat is median of London minus median of Wales, so this is the order 
# we specify in the calculate step

head(null_distribution)
  
```

And now visualise the observed stat against the null distribution;

```{r}
observed_stat_lond_wal <- london_wales %>% 
  specify(pounds_per_hour_worked ~ region) %>% 
  calculate("diff in medians", order = c("london", "wales"))

observed_stat_lond_wal
```


H1 is a "greater than" clause, so that means this is a one-sided test in the
"right" direction.

```{r}
null_distribution %>% 
  visualise(bins = 30) +
  theme_light(base_size = 10) +
  shade_p_value(obs_stat = observed_stat_lond_wal, direction = "right")
```

This gives a p-value of;
```{r}
p_value <- null_distribution %>%
  get_p_value(obs_stat = observed_stat_lond_wal, direction = "right")
p_value
```

The p-value is less than α = 0.05.  In this case we reject the null hypothesis 
and can say that for this data there is a significant difference between the 
median hourly output in London when compared to the median hourly output in Wales.

## Output by Industry by Region 

One other point of interest is the output per industry per region;

```{r}
model_base_data %>% 
  select(region, industry_group, pounds_per_hour_worked) %>% 
  group_by(region, industry_group) %>% 
  ggplot() +
  aes(x = reorder(industry_group, pounds_per_hour_worked),
      y = log(pounds_per_hour_worked), colour = region) +
  geom_point(alpha = 0.3) +
  theme_light() +
  labs(title = "Productivity per Industry by UK Region",
       x = "Industry",
       y = "log(Pounds Output per Hour Worked)") +
  scale_x_discrete(labels = wrap_format(40)) +
  coord_flip()
```

<br>


### Agriculture, Mining, Water, Electricity

This industry grouping shows a very large spread of productivity which appears
to be dependent on region:

```{r}
model_base_data %>% 
  filter(industry == "ABDE") %>% 
  select(region, industry_group, pounds_per_hour_worked) %>% 
  group_by(region, industry_group) %>% 
  ggplot() +
  aes(x = reorder(industry_group, pounds_per_hour_worked),
      y = pounds_per_hour_worked, colour = region) +
  geom_jitter(height = 0.1) +
  theme_light() +
  labs(title = "Agriculture, Mining, Water, Electricity Productivity by UK Region",
       y = "Pounds Output per Hour Worked") +
  theme(axis.title.x = element_blank ()) +
  scale_colour_brewer(palette = "Set3")
```


This clearly shows stratification based on region, but there is insufficient data 
to be able to pinpoint exactly what is creating the difference.


<br>

# Explanatory Model Setup  

```{r}
model_dev <- model_base_data %>% 
  select(-industry)
```

#### Set Test-Train Split

`model_dev` contains over 3600 observations, so an 80/20 train/test split would
give almost 2900 rows for training and around 750 rows for testing.

```{r}

# Change character variables to factors
model_dev <- model_dev %>% 
  mutate(region = as.factor(region),
         industry_group = as.factor(industry_group))


# Make a test index
test_index <- sample(1:nrow(model_dev), size = nrow(model_dev)*0.2)

# Use the test index to create test and training datasets
model_test  <- slice(model_dev, test_index)
model_train <- slice(model_dev, -test_index)
```




#### mod1a - Training Data

```{r}

mod1a_forward <- regsubsets(pounds_per_hour_worked ~ ., 
                            data = model_train,
                            method = "forward")
```

```{r}
summary_mod1a_forward <- summary(mod1a_forward)
summary_mod1a_forward
```

It looks like industry type and region have an influence on productivity, but 
the average number of jobs in each region is insignificant.

```{r}
plot(mod1a_forward, scale = "adjr2")
```

The plot confirms the original suggestion.  Check against BIC:

```{r}
plot(mod1a_forward, scale = "bic")
```


Again, region and industry are the main influencing factors.

Use BIC to determine the optimum number of predictors;

```{r}
plot(summary_mod1a_forward$bic, type = "b")
```

Although only certain industries and regions have been shown to be influential 
predictors, they cannot be selected individually.  If one industry or region
is selected the they all need to be included.

Check which predictors are most significant;
```{r}
mod1a_no_industry <- lm(pounds_per_hour_worked ~ region, 
                        data = model_train)
summary(mod1a_no_industry)
```

```{r}
mod1a_with_industry <- lm(pounds_per_hour_worked ~ industry_group + region, 
                        data = model_train)
summary(mod1a_with_industry)
```

```{r}
anova(mod1a_no_industry, mod1a_with_industry)
```

The model with `industry_group` is more significant than the model without, 
so it should be the main part of the model.

```{r}
autoplot(mod1a_with_industry)
```


### Model with Test Data


```{r}

mod1_test <- regsubsets(pounds_per_hour_worked ~ ., 
                            data = model_test,
                            method = "forward")
```

```{r}
summary_mod1_test <- summary(mod1_test)
summary_mod1_test
```

In the test data, region is less influential.


```{r}
plot(mod1_test, scale = "adjr2")
```

The plot confirms the original suggestion although region is absent from the 
test data result.  Check against BIC:

```{r}
plot(mod1_test, scale = "bic")
```


Again, region and industry are the main influencing factors.

Use BIC to determine the optimum number of predictors;

```{r}
plot(summary_mod1_test$bic, type = "b")
```

Although only certain industries have been shown to be influential predictors, 
they cannot be selected individually.  If one industry or region is selected 
then they all need to be included.

Check which predictors are most significant;
```{r}
mod1_test_no_industry <- lm(pounds_per_hour_worked ~ region, 
                        data = model_dev)
summary(mod1_test_no_industry)
```

```{r}
mod1_test_with_industry <- lm(pounds_per_hour_worked ~ industry_group + region, 
                        data = model_dev)
summary(mod1_test_with_industry)
```

```{r}
anova(mod1_test_no_industry, mod1_test_with_industry)
```

The model with `industry_group` is still more significant than the model without, 
so it should be the main part of the model.

```{r}
autoplot(mod1_test_with_industry)
```


# Explanatory Model Summary

The diagnostic plots show a reasonable residuals v fitted, with a spread over 
the x-axis and a horizontal line, although there is some grouping evident.

The Q-Q plot lies along the line for the most part, although again the relationship
is not completely normal and scale-location shows some evidence of funneling.

In summary, the productivity within the UK can be described as factors of
industry type and region, or:

$$ pounds\_per\_hour\_worked \sim industry\_group + region $$

# Does employee age matter?

Pivot the data longer then change characters to factors;

```{r}
model_ages_long <- model_ages %>% 
  pivot_longer(cols = contains("age"), 
               names_to = "employee_age", 
               values_to = "no_employed") %>% 
  select(-industry) %>% 
  mutate(across(where(is.character), .fns = as.factor))
  
```


```{r}
model_ages_long %>% 
  ggplot() +
  aes(x = year) + 
  geom_line(aes(y = no_employed/1000000, 
      group = employee_age,
      colour = employee_age)) +
#  geom_line(aes(y = pounds_per_hour_worked, group = 1)) +
  geom_text(x = 2003,  y = 28, 
           label = "Pounds per hour worked", 
           colour = "black",
           size = 3) +
  theme_light() +
  labs(title = "UK Employment Numbers per Age Group",
       x = "Year",
       y = "No. Employed (millions)") +
  theme(legend.title = element_blank())
```
# Time Series Productivity Per Industry

```{r}
region_by_industry_output_joined %>% 
  filter(region == "uk") %>% 
  group_by(industry_group) %>% 
  ggplot() +
  aes(x = year,
      y = log(pounds_per_hour_worked),
      group = industry_group,
      colour = industry_group) +
  theme_light() +
  scale_colour_discrete(labels = function(x) str_wrap(x, width = 35)) +
  theme(legend.title = element_blank()) +
  geom_line()
  
```



# Generate a Time Series for Forecasting


```{r}
model_fcast <- region_by_industry_output_joined %>% 
  select(-industry) %>% 
  filter(region == "uk") %>% 
  group_by(year) %>% 
  summarise(annual_total = sum(pounds_per_hour_worked))
  

model_fcast <- tsibble(model_fcast, index = "year")

```


```{r}
model_fcast %>% 
  autoplot(annual_total) +
  theme_light() +
  scale_colour_discrete(labels = function(x) str_wrap(x, width = 35)) +
  theme(legend.title = element_blank()) +
  labs(title = "Autoplot of Total Productivity over Time UK",
       x = "Year",
       y = "Productivity") +
  scale_x_continuous(breaks=seq(1997, 2022, 1))
```


# Forecast Model

```{r}
fit <- model_fcast %>% 
  model(arima = ARIMA(annual_total),
        ets = ETS(annual_total))

fit
```

```{r}
forecast_1 <- fit %>%
  fabletools::forecast(h = "6 years")
forecast_1
```



```{r}

forecast_1 %>% 
autoplot(annual_total) +
    guides(colour = guide_legend(title = "Forecast"))

```

